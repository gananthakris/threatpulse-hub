import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import logging
from collections import Counter

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

sns.set_style("whitegrid")


class MalwareAnalyzer:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.analysis_dir = self.data_dir / "analysis"
        self.analysis_dir.mkdir(parents=True, exist_ok=True)
    
    def analyze_malware_trends(self, samples: List[Dict[str, Any]]) -> Dict[str, Any]:
        df = pd.DataFrame(samples)
        
        if df.empty:
            logger.warning("No data to analyze")
            return {}
        
        analysis = {
            "total_samples": len(df),
            "unique_signatures": df['signature'].nunique() if 'signature' in df else 0,
            "unique_file_types": df['file_type'].nunique() if 'file_type' in df else 0,
            "date_range": self._get_date_range(df),
            "top_malware_families": self._get_top_malware_families(df),
            "file_type_distribution": self._get_file_type_distribution(df),
            "country_distribution": self._get_country_distribution(df),
            "size_statistics": self._get_size_statistics(df),
            "temporal_trends": self._get_temporal_trends(df),
            "hash_diversity": self._get_hash_diversity(df),
            "tag_analysis": self._analyze_tags(df)
        }
        
        return analysis
    
    def _get_date_range(self, df: pd.DataFrame) -> Dict[str, str]:
        if 'first_seen' not in df:
            return {"start": "N/A", "end": "N/A"}
        
        df['first_seen'] = pd.to_datetime(df['first_seen'], errors='coerce')
        valid_dates = df['first_seen'].dropna()
        
        if valid_dates.empty:
            return {"start": "N/A", "end": "N/A"}
        
        return {
            "start": str(valid_dates.min()),
            "end": str(valid_dates.max()),
            "days_covered": (valid_dates.max() - valid_dates.min()).days
        }
    
    def _get_top_malware_families(self, df: pd.DataFrame, top_n: int = 10) -> List[Dict[str, Any]]:
        if 'signature' not in df:
            return []
        
        signature_counts = df['signature'].value_counts().head(top_n)
        
        return [
            {"family": family, "count": int(count), "percentage": round(count/len(df)*100, 2)}
            for family, count in signature_counts.items()
        ]
    
    def _get_file_type_distribution(self, df: pd.DataFrame) -> Dict[str, int]:
        if 'file_type' not in df:
            return {}
        
        return df['file_type'].value_counts().to_dict()
    
    def _get_country_distribution(self, df: pd.DataFrame) -> Dict[str, int]:
        if 'origin_country' not in df:
            return {}
        
        country_counts = df['origin_country'].dropna().value_counts()
        return country_counts.head(20).to_dict()
    
    def _get_size_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        if 'file_size' not in df:
            return {}
        
        df['file_size'] = pd.to_numeric(df['file_size'], errors='coerce')
        sizes = df['file_size'].dropna()
        
        if sizes.empty:
            return {}
        
        return {
            "mean_size_bytes": int(sizes.mean()),
            "median_size_bytes": int(sizes.median()),
            "min_size_bytes": int(sizes.min()),
            "max_size_bytes": int(sizes.max()),
            "mean_size_mb": round(sizes.mean() / (1024*1024), 2),
            "median_size_mb": round(sizes.median() / (1024*1024), 2)
        }
    
    def _get_temporal_trends(self, df: pd.DataFrame) -> Dict[str, Any]:
        if 'first_seen' not in df:
            return {}
        
        df['first_seen'] = pd.to_datetime(df['first_seen'], errors='coerce')
        df = df.dropna(subset=['first_seen'])
        
        if df.empty:
            return {}
        
        df['date'] = df['first_seen'].dt.date
        daily_counts = df.groupby('date').size()
        
        return {
            "daily_average": round(daily_counts.mean(), 2),
            "peak_day": str(daily_counts.idxmax()) if not daily_counts.empty else "N/A",
            "peak_count": int(daily_counts.max()) if not daily_counts.empty else 0,
            "trend": "increasing" if len(daily_counts) > 1 and daily_counts.iloc[-1] > daily_counts.iloc[0] else "stable"
        }
    
    def _get_hash_diversity(self, df: pd.DataFrame) -> Dict[str, int]:
        diversity = {}
        
        for hash_type in ['sha256_hash', 'sha1_hash', 'md5_hash']:
            if hash_type in df:
                unique_hashes = df[hash_type].dropna().nunique()
                diversity[hash_type.replace('_hash', '')] = unique_hashes
        
        return diversity
    
    def _analyze_tags(self, df: pd.DataFrame) -> Dict[str, Any]:
        if 'tags' not in df:
            return {}
        
        all_tags = []
        for tags_str in df['tags'].dropna():
            if tags_str:
                tags_list = [tag.strip() for tag in tags_str.split(',')]
                all_tags.extend(tags_list)
        
        if not all_tags:
            return {}
        
        tag_counter = Counter(all_tags)
        top_tags = dict(tag_counter.most_common(20))
        
        return {
            "total_unique_tags": len(tag_counter),
            "top_tags": top_tags,
            "most_common_tag": tag_counter.most_common(1)[0] if tag_counter else None
        }
    
    def generate_visualizations(self, samples: List[Dict[str, Any]], output_prefix: str = "malware_analysis"):
        df = pd.DataFrame(samples)
        
        if df.empty:
            logger.warning("No data to visualize")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        self._plot_file_type_distribution(df, f"{output_prefix}_file_types_{timestamp}")
        self._plot_malware_families(df, f"{output_prefix}_families_{timestamp}")
        self._plot_temporal_trends(df, f"{output_prefix}_timeline_{timestamp}")
        self._plot_country_distribution(df, f"{output_prefix}_countries_{timestamp}")
        self._plot_size_distribution(df, f"{output_prefix}_sizes_{timestamp}")
    
    def _plot_file_type_distribution(self, df: pd.DataFrame, filename: str):
        if 'file_type' not in df:
            return
        
        plt.figure(figsize=(12, 6))
        file_types = df['file_type'].value_counts().head(15)
        
        plt.subplot(1, 2, 1)
        file_types.plot(kind='bar')
        plt.title('Top 15 File Types')
        plt.xlabel('File Type')
        plt.ylabel('Count')
        plt.xticks(rotation=45, ha='right')
        
        plt.subplot(1, 2, 2)
        file_types.head(10).plot(kind='pie', autopct='%1.1f%%')
        plt.title('Top 10 File Types Distribution')
        plt.ylabel('')
        
        plt.tight_layout()
        output_path = self.analysis_dir / f"{filename}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"File type visualization saved to {output_path}")
    
    def _plot_malware_families(self, df: pd.DataFrame, filename: str):
        if 'signature' not in df:
            return
        
        plt.figure(figsize=(14, 6))
        signatures = df['signature'].value_counts().head(20)
        
        signatures.plot(kind='barh')
        plt.title('Top 20 Malware Families/Signatures')
        plt.xlabel('Count')
        plt.ylabel('Malware Family')
        
        plt.tight_layout()
        output_path = self.analysis_dir / f"{filename}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"Malware families visualization saved to {output_path}")
    
    def _plot_temporal_trends(self, df: pd.DataFrame, filename: str):
        if 'first_seen' not in df:
            return
        
        df['first_seen'] = pd.to_datetime(df['first_seen'], errors='coerce')
        df = df.dropna(subset=['first_seen'])
        
        if df.empty:
            return
        
        plt.figure(figsize=(14, 6))
        
        df['date'] = df['first_seen'].dt.date
        daily_counts = df.groupby('date').size()
        
        plt.subplot(2, 1, 1)
        daily_counts.plot(kind='line', marker='.')
        plt.title('Daily Malware Sample Count')
        plt.xlabel('Date')
        plt.ylabel('Number of Samples')
        plt.grid(True, alpha=0.3)
        
        df['hour'] = df['first_seen'].dt.hour
        hourly_counts = df.groupby('hour').size()
        
        plt.subplot(2, 1, 2)
        hourly_counts.plot(kind='bar')
        plt.title('Malware Samples by Hour of Day')
        plt.xlabel('Hour')
        plt.ylabel('Number of Samples')
        
        plt.tight_layout()
        output_path = self.analysis_dir / f"{filename}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"Temporal trends visualization saved to {output_path}")
    
    def _plot_country_distribution(self, df: pd.DataFrame, filename: str):
        if 'origin_country' not in df:
            return
        
        plt.figure(figsize=(12, 8))
        countries = df['origin_country'].dropna().value_counts().head(20)
        
        if countries.empty:
            return
        
        countries.plot(kind='barh')
        plt.title('Top 20 Countries by Malware Origin')
        plt.xlabel('Number of Samples')
        plt.ylabel('Country')
        
        plt.tight_layout()
        output_path = self.analysis_dir / f"{filename}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"Country distribution visualization saved to {output_path}")
    
    def _plot_size_distribution(self, df: pd.DataFrame, filename: str):
        if 'file_size' not in df:
            return
        
        df['file_size'] = pd.to_numeric(df['file_size'], errors='coerce')
        df['file_size_mb'] = df['file_size'] / (1024 * 1024)
        sizes = df['file_size_mb'].dropna()
        
        if sizes.empty:
            return
        
        plt.figure(figsize=(12, 6))
        
        plt.subplot(1, 2, 1)
        sizes[sizes < sizes.quantile(0.95)].hist(bins=50, edgecolor='black')
        plt.title('File Size Distribution (95th percentile)')
        plt.xlabel('Size (MB)')
        plt.ylabel('Frequency')
        
        plt.subplot(1, 2, 2)
        sizes.plot(kind='box')
        plt.title('File Size Box Plot')
        plt.ylabel('Size (MB)')
        
        plt.tight_layout()
        output_path = self.analysis_dir / f"{filename}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"Size distribution visualization saved to {output_path}")
    
    def generate_report(self, analysis_results: Dict[str, Any], filename_prefix: str = "analysis_report") -> Path:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.analysis_dir / f"{filename_prefix}_{timestamp}.txt"
        
        with open(report_path, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("MALWAREBAZAAR DATA ANALYSIS REPORT\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")
            
            f.write("SUMMARY STATISTICS\n")
            f.write("-" * 40 + "\n")
            f.write(f"Total Samples: {analysis_results.get('total_samples', 0)}\n")
            f.write(f"Unique Signatures: {analysis_results.get('unique_signatures', 0)}\n")
            f.write(f"Unique File Types: {analysis_results.get('unique_file_types', 0)}\n\n")
            
            if 'date_range' in analysis_results:
                f.write("DATE RANGE\n")
                f.write("-" * 40 + "\n")
                date_range = analysis_results['date_range']
                f.write(f"Start: {date_range.get('start', 'N/A')}\n")
                f.write(f"End: {date_range.get('end', 'N/A')}\n")
                f.write(f"Days Covered: {date_range.get('days_covered', 'N/A')}\n\n")
            
            if 'top_malware_families' in analysis_results:
                f.write("TOP MALWARE FAMILIES\n")
                f.write("-" * 40 + "\n")
                for family in analysis_results['top_malware_families']:
                    f.write(f"{family['family']}: {family['count']} ({family['percentage']}%)\n")
                f.write("\n")
            
            if 'size_statistics' in analysis_results:
                f.write("FILE SIZE STATISTICS\n")
                f.write("-" * 40 + "\n")
                size_stats = analysis_results['size_statistics']
                f.write(f"Mean Size: {size_stats.get('mean_size_mb', 0)} MB\n")
                f.write(f"Median Size: {size_stats.get('median_size_mb', 0)} MB\n")
                f.write(f"Min Size: {size_stats.get('min_size_bytes', 0)} bytes\n")
                f.write(f"Max Size: {size_stats.get('max_size_bytes', 0)} bytes\n\n")
            
            if 'temporal_trends' in analysis_results:
                f.write("TEMPORAL TRENDS\n")
                f.write("-" * 40 + "\n")
                trends = analysis_results['temporal_trends']
                f.write(f"Daily Average: {trends.get('daily_average', 0)}\n")
                f.write(f"Peak Day: {trends.get('peak_day', 'N/A')}\n")
                f.write(f"Peak Count: {trends.get('peak_count', 0)}\n")
                f.write(f"Trend: {trends.get('trend', 'N/A')}\n\n")
            
            if 'tag_analysis' in analysis_results:
                tag_data = analysis_results['tag_analysis']
                if tag_data:
                    f.write("TAG ANALYSIS\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"Total Unique Tags: {tag_data.get('total_unique_tags', 0)}\n")
                    if 'most_common_tag' in tag_data and tag_data['most_common_tag']:
                        f.write(f"Most Common Tag: {tag_data['most_common_tag'][0]} ({tag_data['most_common_tag'][1]} occurrences)\n")
                    f.write("\n")
        
        logger.info(f"Analysis report saved to {report_path}")
        return report_path